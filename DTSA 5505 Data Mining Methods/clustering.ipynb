{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a14a6c2c2b245d45b367756d7fe5f7d",
     "grade": false,
     "grade_id": "cell-6ce5cece863df8e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Homework 3 - Clustering\n",
    "***\n",
    "**Name**: $<$insert name here$>$ \n",
    "***\n",
    "\n",
    "Remember that you are encouraged to discuss the problems with your instructors and classmates, but **you must write all code and solutions on your own**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7d8aeda72f4dd210360cbdc224e7dfd",
     "grade": false,
     "grade_id": "cell-5b17602a9843d8ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The rules to be followed for the assignment are:\n",
    "\n",
    "- Do **NOT** load additional packages beyond what we've shared in the cells below.\n",
    "- Some problems with code may be autograded.  If we provide a function or class API **do not** change it.\n",
    "- Do not change the location of the data or data directory.  Use only relative paths to access the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb2ce4604fc1011f91f321ba3e5d9ef9",
     "grade": false,
     "grade_id": "cell-f0584d2146b12be0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c4291993ee82b715be604ef84c536c0e",
     "grade": false,
     "grade_id": "cell-3d05363c25d1c909",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [10 points] Problem 1 - K Means Clustering\n",
    "***\n",
    "\n",
    "A sample dataset has been provided to you in the './data/sample_dataset_kmeans.pickle' path. The centroids are in './data/sample_centroids_kmeans.pickle' and the sample result is in './data/sample_result_kmeans.pickle' path. You can use these to test your code.\n",
    "\n",
    "Here are the attributes for the dataset. Use this dataset to test your functions.\n",
    "\n",
    "- Dataset should load the points in the form of a list of lists where each list item represents a point in the space. \n",
    "- An example dataset will have the following structure. If there are 3 points in the dataset, this would appear as follows in the list of lists.\n",
    "\n",
    "```python\n",
    "dataset = [\n",
    "    [5,6], \n",
    "    [3,5], \n",
    "    [2,8]\n",
    "]\n",
    "  \n",
    "```\n",
    "\n",
    "Note:\n",
    "- A sample dataset to test your code has been provided in the location \"data/sample_dataset_kmeans.pickle\". Please maintain this as it would be necessary while grading.\n",
    "- Do not change the variable names of the returned values.\n",
    "- After calculating each of those values, assign them to the corresponding value that is being returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79ee266c5879de86fc89d344378e6fac",
     "grade": false,
     "grade_id": "cell-fa73c03160fb02d1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def k_means_clustering(centroids, dataset):\n",
    "\n",
    "#   Description: Perform k means clustering for 2 iterations given as input the dataset and centroids.\n",
    "#   Input:\n",
    "#       1. centroids - A list of lists containing the initial centroids for each cluster. \n",
    "#       2. dataset - A list of lists denoting points in the space.\n",
    "#   Output:\n",
    "#       1. results - A dictionary where the key is iteration number and store the cluster assignments in the \n",
    "#           appropriate clusters. Also, update the centroids list after each iteration.\n",
    "\n",
    "    result = {\n",
    "        '1': { 'cluster1': [], 'cluster2': [], 'cluster3': [], 'centroids': []},\n",
    "        '2': { 'cluster1': [], 'cluster2': [], 'cluster3': [], 'centroids': []}\n",
    "    }\n",
    "    \n",
    "    centroid1, centroid2, centroid3 = centroids[0], centroids[1], centroids[2]\n",
    "    \n",
    "    for iteration in range(2):\n",
    "        # your code here\n",
    "        \n",
    "        for point in dataset:\n",
    "            \n",
    "            distances = [\n",
    "                np.sqrt(np.square(point[0] - centroid1[0]) + np.square(point[1] - centroid1[1])),\n",
    "                np.sqrt(np.square(point[0] - centroid2[0]) + np.square(point[1] - centroid2[1])),\n",
    "                np.sqrt(np.square(point[0] - centroid3[0]) + np.square(point[1] - centroid3[1]))\n",
    "            ]\n",
    "            \n",
    "            cluster_index = distances.index(min(distances))\n",
    "            \n",
    "            result[str(iteration+1)]['cluster' + str(cluster_index + 1)].append(point)\n",
    "        \n",
    "        cluster1 = result[str(iteration+1)]['cluster1']\n",
    "        cluster2 = result[str(iteration+1)]['cluster2']\n",
    "        cluster3 = result[str(iteration+1)]['cluster3']\n",
    "        \n",
    "        if len(cluster1) > 0:\n",
    "            new_x = 0\n",
    "            new_y = 0\n",
    "            for item in cluster1:\n",
    "                new_x += item[0]\n",
    "                new_y += item[1]\n",
    "            centroid1 = [new_x/len(cluster1),new_y/len(cluster1)]\n",
    "\n",
    "        if len(cluster2) > 0:\n",
    "            new_x = 0\n",
    "            new_y = 0\n",
    "            for item in cluster2:\n",
    "                new_x += item[0]\n",
    "                new_y += item[1]\n",
    "            centroid2 = [new_x/len(cluster2),new_y/len(cluster2)]\n",
    "\n",
    "        if len(cluster3) > 0:\n",
    "            new_x = 0\n",
    "            new_y = 0\n",
    "            for item in cluster3:\n",
    "                new_x += item[0]\n",
    "                new_y += item[1]\n",
    "            centroid3 = [new_x/len(cluster3),new_y/len(cluster3)]\n",
    "        \n",
    "        result[str(iteration +1)]['centroids'] = [centroid1, centroid2, centroid3]\n",
    "\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d74ac66386f8372fb6948b761216342",
     "grade": false,
     "grade_id": "cell-12fc46d679cb702c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected result value for the given dataset is:\n",
      "{'1': {'centroids': [[23.5, 81.75], [52.5, 28.25], [25.5, 31.5]],\n",
      "       'cluster1': [[23, 96], [29, 99], [30, 64], [12, 68]],\n",
      "       'cluster2': [[46, 33], [82, 20], [57, 51], [25, 9]],\n",
      "       'cluster3': [[26, 21], [25, 42]]},\n",
      " '2': {'centroids': [[23.5, 81.75],\n",
      "                     [61.666666666666664, 34.666666666666664],\n",
      "                     [25.333333333333332, 24.0]],\n",
      "       'cluster1': [[23, 96], [29, 99], [30, 64], [12, 68]],\n",
      "       'cluster2': [[46, 33], [82, 20], [57, 51]],\n",
      "       'cluster3': [[26, 21], [25, 42], [25, 9]]}}\n",
      "\n",
      "Your result value is:\n",
      "{'1': {'centroids': [[23.5, 81.75], [52.5, 28.25], [25.5, 31.5]],\n",
      "       'cluster1': [[23, 96], [29, 99], [30, 64], [12, 68]],\n",
      "       'cluster2': [[46, 33], [82, 20], [57, 51], [25, 9]],\n",
      "       'cluster3': [[26, 21], [25, 42]]},\n",
      " '2': {'centroids': [[23.5, 81.75],\n",
      "                     [61.666666666666664, 34.666666666666664],\n",
      "                     [25.333333333333332, 24.0]],\n",
      "       'cluster1': [[23, 96], [29, 99], [30, 64], [12, 68]],\n",
      "       'cluster2': [[46, 33], [82, 20], [57, 51]],\n",
      "       'cluster3': [[26, 21], [25, 42], [25, 9]]}}\n"
     ]
    }
   ],
   "source": [
    "# This cell has visible test cases that you can run to see if you are on the right track!\n",
    "# Note: hidden tests will also be applied on other randomized datasets for final grading.\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(depth=4)\n",
    "\n",
    "with open('./data/sample_centroids_kmeans.pickle', \"rb\") as fh:\n",
    "     centroids = pickle.load(fh)\n",
    "        \n",
    "with open('./data/sample_dataset_kmeans.pickle', \"rb\") as fh:\n",
    "     dataset = pickle.load(fh)     \n",
    "\n",
    "result = k_means_clustering(centroids,dataset)\n",
    "\n",
    "with open('./data/sample_result_kmeans.pickle', \"rb\") as fh:\n",
    "     result_expected = pickle.load(fh)\n",
    "\n",
    "print(f'The expected result value for the given dataset is:')\n",
    "pp.pprint(result_expected)\n",
    "print(f'\\nYour result value is:')\n",
    "pp.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ce4d9047099ccf8168168ba26674db4",
     "grade": true,
     "grade_id": "cell-6beada533a0abe0c",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# This cell has hidden test cases that will run after you submit your assignment. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb3740b06d0eeb71a34c67ee39cb3d47",
     "grade": false,
     "grade_id": "cell-be657f959b985aa4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [10 points] Problem 2 - Clustering using EM Method\n",
    "***\n",
    "\n",
    "A sample dataset has been provided to you in the './data/sample_dataset_em.pickle' path. The centroids are in './data/sample_centroids_em.pickle' and the sample result is in './data/sample_result_em.pickle' path. You can use these to test your code. \n",
    "\n",
    "Here are the attributes for the dataset. Use this dataset to test your functions.\n",
    "\n",
    "- Dataset should load the points in the form of a list of lists where each list item represents a point in the space. \n",
    "- An example dataset will have the following structure. If there are 3 points in the dataset, this would appear as follows in the list of lists.\n",
    "\n",
    "```python\n",
    "dataset = [5,7,9]\n",
    "  \n",
    "```\n",
    "\n",
    "Note:\n",
    "- A sample dataset to test your code has been provided in the location \"data/em_dataset.pickle\". Please maintain this as it would be necessary while grading.\n",
    "- Do not change the variable names of the returned values.\n",
    "- After calculating each of those values, assign them to the corresponding value that is being returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06b2ebdf9fe997a517e90328aeb305ef",
     "grade": false,
     "grade_id": "cell-00eeb28b483d10a8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def em_clustering(centroids, dataset):\n",
    "\n",
    "#   Input: \n",
    "#       1. centroids - A list of lists with each value representing the mean and standard deviation values picked from a gausian distribution.\n",
    "#       2. dataset - A list of points randomly picked.\n",
    "#   Output:\n",
    "#       1. results - Return the updated centroids(updated mean and std values after the EM step) after the first iteration.\n",
    "\n",
    "    new_centroids = list()\n",
    "    \n",
    "    # your code here\n",
    "    responsibilities = []\n",
    "    \n",
    "    for point in dataset:\n",
    "        \n",
    "        point_responsibilities = []\n",
    "        \n",
    "        for centroid in centroids:\n",
    "            \n",
    "            mean, std = centroid\n",
    "            exponent = - np.square(point-mean) / (2 * np.square(std))\n",
    "            probability = np.exp(exponent) / (std * np.sqrt(2*np.pi))\n",
    "            point_responsibilities.append(probability)\n",
    "            \n",
    "        total = sum(point_responsibilities)\n",
    "        \n",
    "        if total > 0:\n",
    "           \n",
    "            normalized_responsibilities = []\n",
    "            \n",
    "            for p in point_responsibilities:\n",
    "                \n",
    "                normalized_responsibilities.append(p/total)\n",
    "            \n",
    "            point_responsibilities = normalized_responsibilities\n",
    "        \n",
    "        responsibilities.append(point_responsibilities)\n",
    "              \n",
    "    responsibilities = np.array(responsibilities)\n",
    "    \n",
    "    for k in range(len(centroids)):\n",
    "        \n",
    "        sum_responsibilities = sum(responsibilities[:,k])\n",
    "        \n",
    "        if sum_responsibilities > 0:\n",
    "            \n",
    "            weighted_sum = 0\n",
    "            \n",
    "            for i in range(len(dataset)):\n",
    "                \n",
    "                weighted_sum += responsibilities[i,k] * dataset[i]\n",
    "                \n",
    "            new_mean = weighted_sum / sum_responsibilities\n",
    "            \n",
    "            weighted_squared_sum = 0\n",
    "            \n",
    "            for i in range(len(dataset)):\n",
    "            \n",
    "                weighted_squared_sum += responsibilities[i,k] * np.square(dataset[i]-new_mean)\n",
    "            \n",
    "            new_std = np.sqrt(weighted_squared_sum / sum_responsibilities)\n",
    "            \n",
    "            new_centroids.append([new_mean, new_std])\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            new_centroids.append(centroids[k])\n",
    "        \n",
    "    return new_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91ad53d7d2606cbeaf1bef6f86ac17c9",
     "grade": false,
     "grade_id": "cell-33dbf081e1908106",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected result value for the given dataset is:\n",
      "[[13.346550530668159, 3.236599802533008],\n",
      " [7.9971108077796735, 4.473417525043109]]\n",
      "\n",
      "Your result value is:\n",
      "[[13.346550530668159, 3.236599802533008],\n",
      " [7.997110807779673, 4.473417525043108]]\n"
     ]
    }
   ],
   "source": [
    "# This cell has visible test cases that you can run to see if you are on the right track!\n",
    "# Note: hidden tests will also be applied on randomized datasets for final grading.\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(depth=4)\n",
    "\n",
    "with open('./data/sample_centroids_em.pickle', \"rb\") as fh:\n",
    "     centroids = pickle.load(fh)\n",
    "        \n",
    "with open('./data/sample_dataset_em.pickle', \"rb\") as fh:\n",
    "     dataset = pickle.load(fh)\n",
    "\n",
    "new_centroids = em_clustering(centroids,dataset)\n",
    "\n",
    "with open('./data/sample_result_em.pickle', \"rb\") as fh:\n",
    "     new_centroids_expected = pickle.load(fh)\n",
    "\n",
    "print(f'The expected result value for the given dataset is:')\n",
    "pp.pprint(new_centroids_expected)\n",
    "print(f'\\nYour result value is:')\n",
    "pp.pprint(new_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bae4639b485c93815a591805beefb4df",
     "grade": true,
     "grade_id": "cell-475bb00465b45bcc",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# This cell has hidden test cases that will run after you submit your assignment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
